{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow import feature_column\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wiki is run using wiki software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otherwise known as a wiki engine.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A wiki engine is a type of content management ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>but it differs from most other such systems,in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in that the content is created without any def...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                  A wiki is run using wiki software      0\n",
       "1                  otherwise known as a wiki engine.      1\n",
       "2  A wiki engine is a type of content management ...      1\n",
       "3  but it differs from most other such systems,in...      0\n",
       "4  in that the content is created without any def...      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = 'C:\\SoloLearnMachineLearning\\Stackoverflow\\TextDataset.csv'\n",
    "\n",
    "#it is just two column csv, like:\n",
    "# text;label\n",
    "# A wiki is run using wiki software;0\n",
    "# otherwise known as a wiki engine.;1\n",
    "\n",
    "dataframe = pd.read_csv(DATA_PATH, delimiter = ';')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = word_index =  59\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing before feature_clolumn includes\n",
    "# - getting the vocabulary\n",
    "# - tokenization, which means only splitting on tokens. Encoding sentences with vocablary will be done by feature_column!\n",
    "# - padding\n",
    "# - truncating\n",
    "\n",
    "# Build vacabulary\n",
    "vocab_size = 100\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "sentences = dataframe['text'].to_list()\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
    "\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# if word_index shorter then default value of vocab_size we'll save actual size\n",
    "vocab_size=len(word_index)\n",
    "print(\"vocab_size = word_index = \",len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sentensec on tokens. here token = word\n",
    "# text_to_word_sequence() has good default filter for charachters include basic punctuation, tabs, and newlines\n",
    "dataframe['text'] = dataframe['text'].apply(tf.keras.preprocessing.text.text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, wiki, is, run, using, wiki, software]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[otherwise, known, as, a, wiki, engine]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, wiki, engine, is, a, type, of, content, ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, it, differs, from, most, other, such, sy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[in, that, the, content, is, created, without,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          [a, wiki, is, run, using, wiki, software]      0\n",
       "1            [otherwise, known, as, a, wiki, engine]      1\n",
       "2  [a, wiki, engine, is, a, type, of, content, ma...      1\n",
       "3  [but, it, differs, from, most, other, such, sy...      0\n",
       "4  [in, that, the, content, is, created, without,...      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, wiki, is, run, using, wiki]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[otherwise, known, as, a, wiki, engine]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, wiki, engine, is, a, type]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, it, differs, from, most, other]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[in, that, the, content, is, created]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0          [a, wiki, is, run, using, wiki]      0\n",
       "1  [otherwise, known, as, a, wiki, engine]      1\n",
       "2           [a, wiki, engine, is, a, type]      1\n",
       "3    [but, it, differs, from, most, other]      0\n",
       "4    [in, that, the, content, is, created]      0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 6\n",
    "\n",
    "# paddind and trancating setnences\n",
    "# do that directly with strings without using tokenizer.texts_to_sequences()\n",
    "# the feature_colunm will convert strings into numbers\n",
    "dataframe['text']=dataframe['text'].apply(lambda x, N=max_length: (x + N * [''])[:N])\n",
    "dataframe['text']=dataframe['text'].apply(lambda x, N=max_length: x[:N])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method to create tf.data dataset from Pandas Dataframe\n",
    "def df_to_dataset(dataframe, label_column, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    #labels = dataframe.pop(label_column)\n",
    "    labels = dataframe[label_column]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train examples\n",
      "2 validation examples\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and validation sets\n",
    "train_df, val_df = train_test_split(dataframe, test_size=0.2)\n",
    "\n",
    "print(len(train_df), 'train examples')\n",
    "print(len(val_df), 'validation examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds = df_to_dataset(dataframe, 'label',shuffle=False,batch_size=batch_size)\n",
    "\n",
    "train_ds = df_to_dataset(train_df, 'label', batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_df, 'label', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <tf.Tensor: id=8795, shape=(9, 6), dtype=string, numpy=\n",
       " array([[b'a', b'wiki', b'is', b'run', b'using', b'wiki'],\n",
       "        [b'otherwise', b'known', b'as', b'a', b'wiki', b'engine'],\n",
       "        [b'a', b'wiki', b'engine', b'is', b'a', b'type'],\n",
       "        [b'but', b'it', b'differs', b'from', b'most', b'other'],\n",
       "        [b'in', b'that', b'the', b'content', b'is', b'created'],\n",
       "        [b'and', b'wikis', b'have', b'little', b'inherent', b'structure'],\n",
       "        [b'allowing', b'structure', b'to', b'emerge', b'according', b'to'],\n",
       "        [b'there', b'are', b'dozens', b'of', b'different', b'wiki'],\n",
       "        [b'both', b'standalone', b'and', b'part', b'of', b'other']],\n",
       "       dtype=object)>,\n",
       " 'label': <tf.Tensor: id=8794, shape=(9,), dtype=int32, numpy=array([0, 1, 1, 0, 0, 1, 0, 1, 0])>}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and small batch for demo\n",
    "example_batch = next(iter(ds))[0]\n",
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print exxample outputs of for defined feature_column\n",
    "\n",
    "def demo(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())\n",
    "    \n",
    "def seqdemo(feature_column):\n",
    "    feature_layer = tf.keras.experimental.SequenceFeatures(feature_column)\n",
    "    print(feature_layer(example_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=5218, shape=(9, 6, 8), dtype=float32, numpy=\n",
      "array([[[ 0.02763646,  0.46926948,  0.16602302,  0.41979697,\n",
      "          0.10070847, -0.25982472,  0.56686956,  0.24198762],\n",
      "        [-0.17580262, -0.0545252 ,  0.11080994, -0.01236732,\n",
      "         -0.08224947,  0.28997687, -0.44878346,  0.23482987],\n",
      "        [ 0.25610265, -0.28358257,  0.4709215 ,  0.36946535,\n",
      "         -0.04738319, -0.37916708, -0.6918726 ,  0.15008691],\n",
      "        [-0.10372087, -0.15801448,  0.17832626, -0.00092938,\n",
      "         -0.35034904, -0.42338422,  0.2239229 ,  0.31570607],\n",
      "        [-0.52049744,  0.4207177 ,  0.06991487,  0.25887436,\n",
      "         -0.4963163 ,  0.29882333,  0.25331378, -0.25571042],\n",
      "        [-0.17580262, -0.0545252 ,  0.11080994, -0.01236732,\n",
      "         -0.08224947,  0.28997687, -0.44878346,  0.23482987]],\n",
      "\n",
      "       [[-0.4570017 , -0.29725   , -0.26551938, -0.31475785,\n",
      "          0.3716718 ,  0.5617713 , -0.25350043, -0.3703429 ],\n",
      "        [-0.6737758 , -0.46808305, -0.70588297,  0.32659894,\n",
      "          0.48986506, -0.6591468 ,  0.05110093, -0.26870945],\n",
      "        [ 0.4307793 ,  0.29802677,  0.25411236, -0.5028242 ,\n",
      "         -0.2220116 , -0.34800103,  0.2589489 , -0.22024295],\n",
      "        [ 0.02763646,  0.46926948,  0.16602302,  0.41979697,\n",
      "          0.10070847, -0.25982472,  0.56686956,  0.24198762],\n",
      "        [-0.17580262, -0.0545252 ,  0.11080994, -0.01236732,\n",
      "         -0.08224947,  0.28997687, -0.44878346,  0.23482987],\n",
      "        [ 0.15614407,  0.11552305, -0.2827061 , -0.26006672,\n",
      "          0.08384599,  0.41235793,  0.00921086, -0.33908755]],\n",
      "\n",
      "       [[ 0.02763646,  0.46926948,  0.16602302,  0.41979697,\n",
      "          0.10070847, -0.25982472,  0.56686956,  0.24198762],\n",
      "        [-0.17580262, -0.0545252 ,  0.11080994, -0.01236732,\n",
      "         -0.08224947,  0.28997687, -0.44878346,  0.23482987],\n",
      "        [ 0.15614407,  0.11552305, -0.2827061 , -0.26006672,\n",
      "          0.08384599,  0.41235793,  0.00921086, -0.33908755],\n",
      "        [ 0.25610265, -0.28358257,  0.4709215 ,  0.36946535,\n",
      "         -0.04738319, -0.37916708, -0.6918726 ,  0.15008691],\n",
      "        [ 0.02763646,  0.46926948,  0.16602302,  0.41979697,\n",
      "          0.10070847, -0.25982472,  0.56686956,  0.24198762],\n",
      "        [-0.12515073,  0.01965772,  0.13525799, -0.09385514,\n",
      "         -0.50347054,  0.20342661,  0.13098022, -0.03249019]],\n",
      "\n",
      "       [[-0.52657235,  0.06990973,  0.53897345,  0.16719809,\n",
      "          0.00428994,  0.1307766 ,  0.42844737,  0.3242289 ],\n",
      "        [-0.00204597,  0.44208154, -0.11321344, -0.14800584,\n",
      "         -0.10810021,  0.29056644, -0.34561267, -0.03004174],\n",
      "        [-0.14456849,  0.21268669,  0.05475958,  0.28511566,\n",
      "         -0.39302593,  0.45169067,  0.23289894,  0.22953287],\n",
      "        [ 0.13137564, -0.35661185,  0.18343122,  0.30301905,\n",
      "         -0.25264132, -0.02665449, -0.00193478,  0.6317514 ],\n",
      "        [-0.02195241, -0.07645021, -0.30376828, -0.07660118,\n",
      "         -0.6002644 ,  0.15520991,  0.2630242 ,  0.37465006],\n",
      "        [ 0.02787179, -0.35747027, -0.22362232, -0.66047555,\n",
      "          0.2867884 ,  0.4636409 ,  0.00739529, -0.13122602]],\n",
      "\n",
      "       [[ 0.12298331,  0.13579948, -0.31961623,  0.24890365,\n",
      "          0.3700846 ,  0.28361437, -0.07402343, -0.23124076],\n",
      "        [-0.08961768,  0.07942163, -0.11062166, -0.1794695 ,\n",
      "         -0.47265136, -0.13293932, -0.3005725 , -0.61096656],\n",
      "        [ 0.3150017 ,  0.3471566 ,  0.5051626 , -0.06544623,\n",
      "         -0.3847148 , -0.42629665,  0.3593969 ,  0.20786284],\n",
      "        [-0.15583728,  0.00225318,  0.0146646 ,  0.45965585,\n",
      "          0.40351975, -0.08714198,  0.09326763, -0.50178534],\n",
      "        [ 0.25610265, -0.28358257,  0.4709215 ,  0.36946535,\n",
      "         -0.04738319, -0.37916708, -0.6918726 ,  0.15008691],\n",
      "        [ 0.05742102, -0.25552922, -0.4329682 , -0.34648687,\n",
      "          0.01909125, -0.18249615,  0.25574854,  0.3595039 ]],\n",
      "\n",
      "       [[ 0.13851932, -0.36138123,  0.00145312, -0.11357879,\n",
      "         -0.12785637, -0.21643063, -0.12357599,  0.30795076],\n",
      "        [-0.32407913, -0.06517533,  0.35918176,  0.48894465,\n",
      "         -0.15633108,  0.09622087,  0.4594207 ,  0.37883222],\n",
      "        [-0.2521058 ,  0.3685558 , -0.06354833,  0.01727457,\n",
      "         -0.5247108 , -0.42511162, -0.3567974 , -0.00643466],\n",
      "        [-0.25257945, -0.00343417, -0.07436097,  0.55548126,\n",
      "          0.06328963,  0.7021994 , -0.5700142 ,  0.12410294],\n",
      "        [ 0.05663264,  0.32438672,  0.4509803 , -0.22509442,\n",
      "          0.332343  , -0.2892738 ,  0.307411  ,  0.28840315],\n",
      "        [-0.13623859,  0.34522578, -0.13458696,  0.6064557 ,\n",
      "          0.3979982 , -0.28256327,  0.16909285, -0.2028116 ]],\n",
      "\n",
      "       [[ 0.29682797,  0.30005452,  0.12902038, -0.29437476,\n",
      "         -0.15035865,  0.28033733,  0.19396044,  0.4654367 ],\n",
      "        [-0.13623859,  0.34522578, -0.13458696,  0.6064557 ,\n",
      "          0.3979982 , -0.28256327,  0.16909285, -0.2028116 ],\n",
      "        [ 0.44109976, -0.56010216, -0.33245626, -0.24678116,\n",
      "          0.3100359 , -0.22903864, -0.07503849,  0.18222553],\n",
      "        [ 0.19538969,  0.16768877, -0.3116164 ,  0.43260106,\n",
      "         -0.17208937, -0.36337984, -0.2643181 , -0.15303275],\n",
      "        [ 0.30961445, -0.03692716, -0.5549776 ,  0.3143871 ,\n",
      "         -0.09918627,  0.19026409,  0.1864984 , -0.06447884],\n",
      "        [ 0.44109976, -0.56010216, -0.33245626, -0.24678116,\n",
      "          0.3100359 , -0.22903864, -0.07503849,  0.18222553]],\n",
      "\n",
      "       [[-0.26655194,  0.51016325, -0.1941655 , -0.4737162 ,\n",
      "         -0.03229135,  0.09238537, -0.60550916, -0.17423883],\n",
      "        [-0.4004417 , -0.01708393, -0.54242617, -0.38922438,\n",
      "         -0.34065366,  0.08636072, -0.1968602 ,  0.09125239],\n",
      "        [-0.17622282,  0.48106217, -0.47681496, -0.12738232,\n",
      "         -0.46978995, -0.06997018, -0.12851511,  0.24364802],\n",
      "        [-0.21919642, -0.24477589, -0.14079101, -0.18614796,\n",
      "          0.18777338,  0.49807826, -0.19906883,  0.3549213 ],\n",
      "        [ 0.2511534 , -0.22206299, -0.4942706 , -0.0501112 ,\n",
      "          0.2322025 , -0.14236778,  0.23190793, -0.2111053 ],\n",
      "        [-0.17580262, -0.0545252 ,  0.11080994, -0.01236732,\n",
      "         -0.08224947,  0.28997687, -0.44878346,  0.23482987]],\n",
      "\n",
      "       [[-0.34445244, -0.31148928, -0.12336952,  0.6264396 ,\n",
      "          0.4010056 ,  0.02479612, -0.17941228, -0.15298527],\n",
      "        [ 0.1342758 , -0.02269644,  0.24206199,  0.491977  ,\n",
      "         -0.19387883,  0.6757937 , -0.07826561, -0.11214136],\n",
      "        [ 0.13851932, -0.36138123,  0.00145312, -0.11357879,\n",
      "         -0.12785637, -0.21643063, -0.12357599,  0.30795076],\n",
      "        [ 0.30244017, -0.30020216, -0.3199646 , -0.11516992,\n",
      "         -0.00470731, -0.6295897 , -0.04554646,  0.27145395],\n",
      "        [-0.21919642, -0.24477589, -0.14079101, -0.18614796,\n",
      "          0.18777338,  0.49807826, -0.19906883,  0.3549213 ],\n",
      "        [ 0.02787179, -0.35747027, -0.22362232, -0.66047555,\n",
      "          0.2867884 ,  0.4636409 ,  0.00739529, -0.13122602]]],\n",
      "      dtype=float32)>, <tf.Tensor: id=5206, shape=(9,), dtype=int64, numpy=array([6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int64)>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define categorical colunm for our text feature, which is preprocessed into lists of tokens\n",
    "# Note that key name should be the same as original column name in dataframe\n",
    "text_column = feature_column.sequence_categorical_column_with_vocabulary_list(key='text', \n",
    "                                                                     vocabulary_list=list(word_index))\n",
    "\n",
    "# arguemnt dimention here is exactly the dimension of the space in which tokens will be presented during model's learning\n",
    "# see the tutorial at https://www.tensorflow.org/beta/tutorials/text/word_embeddings\n",
    "text_embedding = feature_column.embedding_column(text_column, dimension=8)\n",
    "print(seqdemo(text_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The define the layers and model it self\n",
    "# This example uses Keras Functional API instead of Sequential just for more generallity\n",
    "\n",
    "# Define SequenceFeatures layer to pass feature_columns into Keras model\n",
    "sequence_feature_layer = tf.keras.experimental.SequenceFeatures(text_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': <tf.Tensor 'text_8:0' shape=(None, 6) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "# Define inputs for each feature column. See\n",
    "# см. https://github.com/tensorflow/tensorflow/issues/27416#issuecomment-502218673\n",
    "feature_layer_inputs = {}\n",
    "sequence_feature_layer_inputs = {}\n",
    "\n",
    "# Here we have just one column\n",
    "\n",
    "sequence_feature_layer_inputs['text'] = tf.keras.Input(shape=(max_length,), name='text', dtype=tf.string)\n",
    "print(sequence_feature_layer_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sequence_features_1_6/Identity:0\", shape=(None, None, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sequence_feature_layer_outputs, _ = sequence_feature_layer(sequence_feature_layer_inputs)\n",
    "print(sequence_feature_layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sequence_features_1_7/Identity:0\", shape=(None, None, 8), dtype=float32)\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "sequence_features_1 (Sequenc ((None, None, 8), (None,) 472       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 8)           264       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, None, 256)         2304      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, None, 1)           257       \n",
      "=================================================================\n",
      "Total params: 3,297\n",
      "Trainable params: 3,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define outputs of SequenceFeatures layer \n",
    "# And accually use them as first layer of the model\n",
    "\n",
    "# note here that SequenceFeatures layer produce tuple of two tensors as output. We need just first to pass next.\n",
    "sequence_feature_layer_outputs, _ = sequence_feature_layer(sequence_feature_layer_inputs)\n",
    "print(sequence_feature_layer_outputs)\n",
    "# Add consequences layers. See https://keras.io/getting-started/functional-api-guide/\n",
    "\n",
    "# Conv1D and MaxPooling1D will learn features from words order\n",
    "x = tf.keras.layers.Conv1D(8,4)(sequence_feature_layer_outputs)\n",
    "x = tf.keras.layers.MaxPooling1D(2)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# This example supposes binary classification, as labels are 0 or 1\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[v for v in sequence_feature_layer_inputs.values()], outputs=x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# This example supposes binary classification, as labels are 0 or 1\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              #run_eagerly=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6024 - accuracy: 0.7143 - val_loss: 0.9619 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6017 - accuracy: 0.7143 - val_loss: 0.9760 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6013 - accuracy: 0.7143 - val_loss: 0.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6022 - accuracy: 0.7143 - val_loss: 1.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6006 - accuracy: 0.7143 - val_loss: 1.0140 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Note that fit() method looking up features in train_ds and valdation_ds by name in \n",
    "# tf.keras.Input(shape=(max_length,), name='text'\n",
    "\n",
    "# This model of cause will learn nothing because of fake data.\n",
    "\n",
    "num_epochs = 5\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
