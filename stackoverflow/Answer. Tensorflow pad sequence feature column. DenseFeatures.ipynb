{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow import feature_column\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wiki is run using wiki software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otherwise known as a wiki engine.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A wiki engine is a type of content management ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>but it differs from most other such systems,in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in that the content is created without any def...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                  A wiki is run using wiki software      0\n",
       "1                  otherwise known as a wiki engine.      1\n",
       "2  A wiki engine is a type of content management ...      1\n",
       "3  but it differs from most other such systems,in...      0\n",
       "4  in that the content is created without any def...      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = 'C:\\SoloLearnMachineLearning\\Stackoverflow\\TextDataset.csv'\n",
    "\n",
    "#it is just two column csv, like:\n",
    "# text;label\n",
    "# A wiki is run using wiki software;0\n",
    "# otherwise known as a wiki engine.;1\n",
    "\n",
    "dataframe = pd.read_csv(DATA_PATH, delimiter = ';')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = word_index =  59\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing before feature_clolumn includes\n",
    "# - getting the vocabulary\n",
    "# - tokenization, which means only splitting on tokens. Encoding sentences with vocablary will be done by feature_column!\n",
    "# - padding\n",
    "# - truncating\n",
    "\n",
    "# Build vacabulary\n",
    "vocab_size = 100\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "sentences = dataframe['text'].to_list()\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
    "\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# if word_index shorter then default value of vocab_size we'll save actual size\n",
    "vocab_size=len(word_index)\n",
    "print(\"vocab_size = word_index = \",len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sentensec on tokens. here token = word\n",
    "# text_to_word_sequence() has good default filter for charachters include basic punctuation, tabs, and newlines\n",
    "dataframe['text'] = dataframe['text'].apply(tf.keras.preprocessing.text.text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, wiki, is, run, using, wiki, software]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[otherwise, known, as, a, wiki, engine]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, wiki, engine, is, a, type, of, content, ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, it, differs, from, most, other, such, sy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[in, that, the, content, is, created, without,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          [a, wiki, is, run, using, wiki, software]      0\n",
       "1            [otherwise, known, as, a, wiki, engine]      1\n",
       "2  [a, wiki, engine, is, a, type, of, content, ma...      1\n",
       "3  [but, it, differs, from, most, other, such, sy...      0\n",
       "4  [in, that, the, content, is, created, without,...      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, wiki, is, run, using, wiki]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[otherwise, known, as, a, wiki, engine]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, wiki, engine, is, a, type]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, it, differs, from, most, other]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[in, that, the, content, is, created]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0          [a, wiki, is, run, using, wiki]      0\n",
       "1  [otherwise, known, as, a, wiki, engine]      1\n",
       "2           [a, wiki, engine, is, a, type]      1\n",
       "3    [but, it, differs, from, most, other]      0\n",
       "4    [in, that, the, content, is, created]      0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 6\n",
    "\n",
    "# paddind and trancating setnences\n",
    "# do that directly with strings without using tokenizer.texts_to_sequences()\n",
    "# the feature_colunm will convert strings into numbers\n",
    "dataframe['text']=dataframe['text'].apply(lambda x, N=max_length: (x + N * [''])[:N])\n",
    "dataframe['text']=dataframe['text'].apply(lambda x, N=max_length: x[:N])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method to create tf.data dataset from Pandas Dataframe\n",
    "def df_to_dataset(dataframe, label_column, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    #labels = dataframe.pop(label_column)\n",
    "    labels = dataframe[label_column]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train examples\n",
      "2 validation examples\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and validation sets\n",
    "train_df, val_df = train_test_split(dataframe, test_size=0.2)\n",
    "\n",
    "print(len(train_df), 'train examples')\n",
    "print(len(val_df), 'validation examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds = df_to_dataset(dataframe, 'label',shuffle=False,batch_size=batch_size)\n",
    "\n",
    "train_ds = df_to_dataset(train_df, 'label', batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_df, 'label', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <tf.Tensor: id=8795, shape=(9, 6), dtype=string, numpy=\n",
       " array([[b'a', b'wiki', b'is', b'run', b'using', b'wiki'],\n",
       "        [b'otherwise', b'known', b'as', b'a', b'wiki', b'engine'],\n",
       "        [b'a', b'wiki', b'engine', b'is', b'a', b'type'],\n",
       "        [b'but', b'it', b'differs', b'from', b'most', b'other'],\n",
       "        [b'in', b'that', b'the', b'content', b'is', b'created'],\n",
       "        [b'and', b'wikis', b'have', b'little', b'inherent', b'structure'],\n",
       "        [b'allowing', b'structure', b'to', b'emerge', b'according', b'to'],\n",
       "        [b'there', b'are', b'dozens', b'of', b'different', b'wiki'],\n",
       "        [b'both', b'standalone', b'and', b'part', b'of', b'other']],\n",
       "       dtype=object)>,\n",
       " 'label': <tf.Tensor: id=8794, shape=(9,), dtype=int32, numpy=array([0, 1, 1, 0, 0, 1, 0, 1, 0])>}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and small batch for demo\n",
    "example_batch = next(iter(ds))[0]\n",
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print exxample outputs of for defined feature_column\n",
    "\n",
    "def demo(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03299773  0.04184001  0.17305394 -0.10351998  0.24569821  0.01226812\n",
      "   0.27817583  0.30197006]\n",
      " [-0.1043179  -0.01837785 -0.01381511 -0.03220359  0.15954606  0.05917749\n",
      "   0.05795546  0.01563778]\n",
      " [-0.05607197 -0.02527429  0.07978318  0.14720751  0.2794927   0.04287523\n",
      "   0.25850403  0.19377325]\n",
      " [ 0.07350308 -0.23727673  0.13429964 -0.0194941  -0.24571379  0.04162838\n",
      "   0.14751883 -0.08218185]\n",
      " [ 0.03584204 -0.00918533 -0.14659135  0.06430952  0.01621727 -0.26398554\n",
      "  -0.01942689 -0.00850088]\n",
      " [ 0.08163229 -0.1261514  -0.05322057  0.08714375 -0.05407189 -0.00263421\n",
      "   0.0985572  -0.30115566]\n",
      " [-0.12511198  0.18405785  0.09329632 -0.18177591 -0.09600383  0.06061305\n",
      "   0.00398835 -0.02046853]\n",
      " [-0.16781782  0.07488805  0.05551051  0.07886202  0.2468106  -0.10796698\n",
      "  -0.06418636  0.23420854]\n",
      " [ 0.09131869 -0.21122038  0.09569611  0.04256458 -0.07726997 -0.1433203\n",
      "   0.07138547  0.02170739]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define categorical colunm for our text feature, which is preprocessed into lists of tokens\n",
    "# Note that key name should be the same as original column name in dataframe\n",
    "text_column = feature_column.categorical_column_with_vocabulary_list(key='text', \n",
    "                                                                     vocabulary_list=list(word_index))\n",
    "\n",
    "#indicator_column produce one-hot-encoding. These lines just to compare with embedding\n",
    "#print(demo(feature_column.indicator_column(payment_description_3)))\n",
    "#print(payment_description_2,'\\n')\n",
    "\n",
    "# arguemnt dimention here is exactly the dimension of the space in which tokens will be presented during model's learning\n",
    "# see the tutorial at https://www.tensorflow.org/beta/tutorials/text/word_embeddings\n",
    "text_embedding = feature_column.embedding_column(text_column, dimension=8)\n",
    "print(demo(text_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The define the layers and model it self\n",
    "# This example uses Keras Functional API instead of Sequential just for more generallity\n",
    "\n",
    "# Define DenseFeatures layer to pass feature_columns into Keras model\n",
    "feature_layer = tf.keras.layers.DenseFeatures(text_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': <tf.Tensor 'text_9:0' shape=(None, 6) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "# Define inputs for each feature column. See\n",
    "# см. https://github.com/tensorflow/tensorflow/issues/27416#issuecomment-502218673\n",
    "feature_layer_inputs = {}\n",
    "\n",
    "# Here we have just one column\n",
    "feature_layer_inputs['text'] = tf.keras.Input(shape=(max_length,), name='text', dtype=tf.string)\n",
    "print(feature_layer_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_features_12_1/Identity:0\", shape=(None, 8), dtype=float32)\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_features_12 (DenseFeat (None, 8)                 472       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,033\n",
      "Trainable params: 3,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define outputs of DenseFeatures layer \n",
    "# And accually use them as first layer of the model\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "print(feature_layer_outputs)\n",
    "\n",
    "# Add consequences layers. See https://keras.io/getting-started/functional-api-guide/\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(feature_layer_outputs)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# This example supposes binary classification, as labels are 0 or 1\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# This example supposes binary classification, as labels are 0 or 1\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              #run_eagerly=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7000 - accuracy: 0.2857 - val_loss: 0.6840 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6948 - accuracy: 0.4286 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.8571 - val_loss: 0.6976 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5714 - val_loss: 0.7044 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.7143 - val_loss: 0.7111 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Note that fit() method looking up features in train_ds and valdation_ds by name in \n",
    "# tf.keras.Input(shape=(max_length,), name='text'\n",
    "\n",
    "# This model of cause will learn nothing because of fake data.\n",
    "\n",
    "num_epochs = 5\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
