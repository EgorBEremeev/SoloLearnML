{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow import feature_column\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wiki is run using wiki software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otherwise known as a wiki engine.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A wiki engine is a type of content management ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>but it differs from most other such systems,in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in that the content is created without any def...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                  A wiki is run using wiki software      0\n",
       "1                  otherwise known as a wiki engine.      1\n",
       "2  A wiki engine is a type of content management ...      1\n",
       "3  but it differs from most other such systems,in...      0\n",
       "4  in that the content is created without any def...      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = 'C:\\SoloLearnMachineLearning\\Stackoverflow\\TextDataset.csv'\n",
    "\n",
    "#it is just two column csv, like:\n",
    "# text;label\n",
    "# A wiki is run using wiki software;0\n",
    "# otherwise known as a wiki engine.;1\n",
    "\n",
    "dataframe = pd.read_csv(DATA_PATH, delimiter = ';')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = word_index =  59\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing before feature_clolumn includes\n",
    "# - getting the vocabulary\n",
    "# - tokenization, which means only splitting on tokens. Encoding sentences with vocablary will be done by feature_column!\n",
    "# - padding\n",
    "# - truncating\n",
    "\n",
    "# Build vacabulary\n",
    "vocab_size = 100\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "sentences = dataframe['text'].to_list()\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\n",
    "\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# if word_index shorter then default value of vocab_size we'll save actual size\n",
    "vocab_size=len(word_index)\n",
    "print(\"vocab_size = word_index = \",len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sentensec on tokens. here token = word\n",
    "# text_to_word_sequence() has good default filter for charachters include basic punctuation, tabs, and newlines\n",
    "dataframe['text'] = dataframe['text'].apply(tf.keras.preprocessing.text.text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, wiki, is, run, using, wiki, software]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[otherwise, known, as, a, wiki, engine]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, wiki, engine, is, a, type, of, content, ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, it, differs, from, most, other, such, sy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[in, that, the, content, is, created, without,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0          [a, wiki, is, run, using, wiki, software]      0\n",
       "1            [otherwise, known, as, a, wiki, engine]      1\n",
       "2  [a, wiki, engine, is, a, type, of, content, ma...      1\n",
       "3  [but, it, differs, from, most, other, such, sy...      0\n",
       "4  [in, that, the, content, is, created, without,...      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, wiki, is, run, using, wiki]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[otherwise, known, as, a, wiki, engine]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, wiki, engine, is, a, type]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, it, differs, from, most, other]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[in, that, the, content, is, created]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0          [a, wiki, is, run, using, wiki]      0\n",
       "1  [otherwise, known, as, a, wiki, engine]      1\n",
       "2           [a, wiki, engine, is, a, type]      1\n",
       "3    [but, it, differs, from, most, other]      0\n",
       "4    [in, that, the, content, is, created]      0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 6\n",
    "\n",
    "# paddind and trancating setnences\n",
    "# do that directly with strings without using tokenizer.texts_to_sequences()\n",
    "# the feature_colunm will convert strings into numbers\n",
    "dataframe['text']=dataframe['text'].apply(lambda x, N=max_length: (x + N * [''])[:N])\n",
    "dataframe['text']=dataframe['text'].apply(lambda x, N=max_length: x[:N])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method to create tf.data dataset from Pandas Dataframe\n",
    "def df_to_dataset(dataframe, label_column, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    #labels = dataframe.pop(label_column)\n",
    "    labels = dataframe[label_column]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train examples\n",
      "2 validation examples\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into train and validation sets\n",
    "train_df, val_df = train_test_split(dataframe, test_size=0.2)\n",
    "\n",
    "print(len(train_df), 'train examples')\n",
    "print(len(val_df), 'validation examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds = df_to_dataset(dataframe, 'label',shuffle=False,batch_size=batch_size)\n",
    "\n",
    "train_ds = df_to_dataset(train_df, 'label',  shuffle=False, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_df, 'label', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <tf.Tensor: id=3387, shape=(9, 6), dtype=string, numpy=\n",
       " array([[b'a', b'wiki', b'is', b'run', b'using', b'wiki'],\n",
       "        [b'otherwise', b'known', b'as', b'a', b'wiki', b'engine'],\n",
       "        [b'a', b'wiki', b'engine', b'is', b'a', b'type'],\n",
       "        [b'but', b'it', b'differs', b'from', b'most', b'other'],\n",
       "        [b'in', b'that', b'the', b'content', b'is', b'created'],\n",
       "        [b'and', b'wikis', b'have', b'little', b'inherent', b'structure'],\n",
       "        [b'allowing', b'structure', b'to', b'emerge', b'according', b'to'],\n",
       "        [b'there', b'are', b'dozens', b'of', b'different', b'wiki'],\n",
       "        [b'both', b'standalone', b'and', b'part', b'of', b'other']],\n",
       "       dtype=object)>,\n",
       " 'label': <tf.Tensor: id=3386, shape=(9,), dtype=int32, numpy=array([0, 1, 1, 0, 0, 1, 0, 1, 0])>}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and small batch for demo\n",
    "example_batch = next(iter(ds))[0]\n",
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print exxample outputs of for defined feature_column\n",
    "\n",
    "def demo(feature_column):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17686643 -0.2989895   0.00264741 -0.3476688  -0.05737228 -0.18041377\n",
      "  -0.00098308  0.325977  ]\n",
      " [ 0.00710045 -0.00310291 -0.02391201 -0.14713128 -0.04860273 -0.14387627\n",
      "   0.0257867  -0.02231171]\n",
      " [-0.10285576 -0.18304147 -0.00298556  0.01808989 -0.16199614 -0.08612611\n",
      "   0.1993926   0.15643066]\n",
      " [ 0.12189802 -0.14372785 -0.0255752  -0.11260048 -0.17380564 -0.10022938\n",
      "  -0.17018622 -0.33584765]\n",
      " [-0.14319299 -0.07304262 -0.02680805  0.10860274 -0.03133818  0.05705167\n",
      "   0.09285476  0.02952158]\n",
      " [ 0.0521474  -0.04482817  0.0456489  -0.09259579  0.0093843  -0.09475025\n",
      "  -0.12256879  0.24423139]\n",
      " [-0.11564245  0.11739489  0.07430411 -0.10169675 -0.24093457  0.06556444\n",
      "  -0.00776027  0.20457251]\n",
      " [-0.09204625 -0.04545312 -0.07439894 -0.20941615 -0.09087479 -0.00044735\n",
      "   0.03422147 -0.19390172]\n",
      " [-0.1145098   0.17188363 -0.12575074  0.07546506  0.00690869  0.01805285\n",
      "   0.14318828 -0.04583522]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define categorical colunm for our text feature, which is preprocessed into lists of tokens\n",
    "# Note that key name should be the same as original column name in dataframe\n",
    "text_column = feature_column.categorical_column_with_vocabulary_list(key='text', \n",
    "                                                                     vocabulary_list=list(word_index))\n",
    "\n",
    "#indicator_column produce one-hot-encoding. These lines just to compare with embedding\n",
    "#print(demo(feature_column.indicator_column(payment_description_3)))\n",
    "#print(payment_description_2,'\\n')\n",
    "\n",
    "# arguemnt dimention here is exactly the dimension of the space in which tokens will be presented during model's learning\n",
    "# see the tutorial at https://www.tensorflow.org/beta/tutorials/text/word_embeddings\n",
    "text_embedding = feature_column.embedding_column(text_column, dimension=8)\n",
    "print(demo(text_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The define the layers and model it self\n",
    "# This example uses Keras Functional API instead of Sequential just for more generallity\n",
    "\n",
    "# Define DenseFeatures layer to pass feature_columns into Keras model\n",
    "feature_layer = tf.keras.layers.DenseFeatures(text_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': <tf.Tensor 'text_4:0' shape=(None, 6) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "# Define inputs for each feature column. See\n",
    "# см. https://github.com/tensorflow/tensorflow/issues/27416#issuecomment-502218673\n",
    "feature_layer_inputs = {}\n",
    "\n",
    "# Here we have just one column\n",
    "feature_layer_inputs['text'] = tf.keras.Input(shape=(max_length,), name='text', dtype=tf.string)\n",
    "print(feature_layer_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_features_6/Identity:0\", shape=(None, 8), dtype=float32)\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_features_6 (DenseFeatu (None, 8)                 472       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,033\n",
      "Trainable params: 3,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define outputs of DenseFeatures layer \n",
    "# And accually use them as first layer of the model\n",
    "feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "print(feature_layer_outputs)\n",
    "\n",
    "# Add consequences layers. See https://keras.io/getting-started/functional-api-guide/\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(feature_layer_outputs)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# This example supposes binary classification, as labels are 0 or 1\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# This example supposes binary classification, as labels are 0 or 1\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              #run_eagerly=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0823 14:13:15.540783 18764 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6900 - accuracy: 0.7143 - val_loss: 0.7230 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6867 - accuracy: 0.5714 - val_loss: 0.7294 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.8571 - val_loss: 0.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6763 - accuracy: 0.7143 - val_loss: 0.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6683 - accuracy: 0.8571 - val_loss: 0.7485 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Note that fit() method looking up features in train_ds and valdation_ds by name in \n",
    "# tf.keras.Input(shape=(max_length,), name='text'\n",
    "\n",
    "# This model of cause will learn nothing because of fake data.\n",
    "\n",
    "num_epochs = 5\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
